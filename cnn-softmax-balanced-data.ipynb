{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0695bf",
   "metadata": {},
   "source": [
    "## !!! Deep Patient Similarity using CNN Softmax using a balanced dataset !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "100f8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "db15be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 98\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92190b48",
   "metadata": {},
   "source": [
    "### Loading data (balanced)\n",
    "\n",
    "* Re-using the saved pre-processed data of patients grouped by visits. \n",
    "* In the pre-processing each patient is clipped to have 40 visits and 42 features. \n",
    "* Picking only 2000 patients for target label N180 to make it balanced with the other targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "620a0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.load(\"p_x.pt\")\n",
    "Y = torch.load(\"p_y.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "543f3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb = []\n",
    "Yb = []\n",
    "n180_c = 0\n",
    "for x, y in zip(X, Y):\n",
    "    if y == \"N180\":\n",
    "        if n180_c < 2000:\n",
    "            n180_c = n180_c + 1\n",
    "            Xb.append(x)\n",
    "            Yb.append(y)\n",
    "    else: \n",
    "        Xb.append(x)\n",
    "        Yb.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "b31e1748",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xb\n",
    "Y = Yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "20c16b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7514\n",
      "7514\n",
      "{'E142', 'I10', 'N088', 'N083', 'N180', 'I120', 'N188', 'E102', 'N039', 'N189'}\n"
     ]
    }
   ],
   "source": [
    "print(len(Y))\n",
    "print(len(X))\n",
    "print(set(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653e84a",
   "metadata": {},
   "source": [
    "### Number of patients in each target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "64f758b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E142: 164\n",
      "I10: 367\n",
      "N088: 130\n",
      "N083: 310\n",
      "N180: 2000\n",
      "I120: 1204\n",
      "N188: 299\n",
      "E102: 102\n",
      "N039: 296\n",
      "N189: 2642\n"
     ]
    }
   ],
   "source": [
    "for l in set(Y):\n",
    "    print(f\"{l}:\", len(np.where(np.array(Y) == l)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c35caab",
   "metadata": {},
   "source": [
    "### Converting target lables to one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "fb4a7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = list(set(Y))\n",
    "Y_oh = np.zeros((len(Y), len(y_labels)))\n",
    "for idx, y in enumerate(Y):\n",
    "    Y_oh[idx][y_labels.index(y)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "d4551dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7514, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_oh.shape)\n",
    "Y_oh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7e0a1",
   "metadata": {},
   "source": [
    "### Converting patient data (X) and target one-hot encoded data (Y_oh) as tensors to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "2f326987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xt shape: torch.Size([7514, 40, 42])\n",
      "Yt shape: torch.Size([7514, 10])\n"
     ]
    }
   ],
   "source": [
    "Xt = torch.tensor(X)\n",
    "Yt = torch.tensor(Y_oh)\n",
    "Xt = Xt.type(torch.FloatTensor)\n",
    "Yt = Yt.type(torch.LongTensor)\n",
    "print(\"Xt shape:\", Xt.shape)\n",
    "print(\"Yt shape:\", Yt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8081911",
   "metadata": {},
   "source": [
    "### A custom dataset to load pairwise data. We are just picking adjacent patient data as pair to learn patient similiarity. Data is shuffled by dataloader for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "d11bcec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n = len(X)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x1 = self.X[idx]\n",
    "        y1 = self.y[idx]\n",
    "        if idx+1 == self.n:\n",
    "            x2 = self.X[idx]\n",
    "            y2 = self.y[idx]\n",
    "        else:\n",
    "            x2 = self.X[idx+1]\n",
    "            y2 = self.y[idx+1]\n",
    "        \n",
    "        y = int(np.array_equal(y1, y2))\n",
    "        \n",
    "        return [x1, x2, np.asarray([y]), y1, y2]\n",
    "\n",
    "    def get_splits(self, n_test=0.2):\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        \n",
    "        return random_split(self, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "08d3e8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train batches: 188\n",
      "# of test batches: 47\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32 \n",
    "\n",
    "dataset = PairwiseDataset(Xt, Yt)\n",
    "train, test = dataset.get_splits()\n",
    "train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(\"# of train batches:\", len(train_dl))\n",
    "print(\"# of test batches:\", len(test_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "28ed2dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a batch x1: torch.Size([32, 40, 42])\n",
      "Shape of a batch y1: torch.Size([32, 10])\n",
      "Shape of a batch x2: torch.Size([32, 40, 42])\n",
      "Shape of a batch y2: torch.Size([32, 10])\n",
      "Shape of a batch y: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_dl)\n",
    "x1, x2, y, y1, y2 = next(train_iter)\n",
    "\n",
    "print('Shape of a batch x1:', x1.shape)\n",
    "print('Shape of a batch y1:', y1.shape)\n",
    "print('Shape of a batch x2:', x2.shape)\n",
    "print('Shape of a batch y2:', y2.shape)\n",
    "print('Shape of a batch y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fccbcd",
   "metadata": {},
   "source": [
    "### CNN_softmax model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "2d289916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNSoftMax(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNSoftMax, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(42, 84, kernel_size=2, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(84, 128, kernel_size=2, stride=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1152, 32)\n",
    "    \n",
    "        self.fc2 = nn.Linear(65, 10)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        x = np.transpose(x, axes=[0, 2, 1])\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self._forward(x1)\n",
    "        x2 = self._forward(x2)\n",
    "        \n",
    "        f_out1 = x1.flatten(start_dim=1)\n",
    "        f_out2 = x2.flatten(start_dim=1)\n",
    "        \n",
    "        f_out1 = self.fc1(f_out1)\n",
    "        f_out2 = self.fc1(f_out2)\n",
    "        \n",
    "        distance = torch.pairwise_distance(f_out1, f_out2, p=2)\n",
    "        distance = distance.reshape(distance.shape[0], 1)\n",
    "\n",
    "        x_f = torch.cat((distance, f_out1, f_out2), 1)\n",
    "        \n",
    "        y_f = self.fc2(x_f)\n",
    "        y_hat = self.softmax(y_f)\n",
    " \n",
    "        return distance, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "7fd032a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNSoftMax(\n",
       "  (conv1): Conv1d(42, 84, kernel_size=(2,), stride=(1,))\n",
       "  (relu): ReLU()\n",
       "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(84, 128, kernel_size=(2,), stride=(1,))\n",
       "  (fc1): Linear(in_features=1152, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=65, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNSoftMax()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "00bb505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, \\\n",
    "precision_recall_fscore_support, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def model_metrics(y_test, y_pred):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "    return acc, p, r, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a229903",
   "metadata": {},
   "source": [
    "### Contrastive loss to distinguish the pairs\n",
    "\n",
    "https://ieeexplore.ieee.org/document/1640964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "1ad8779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, distance, y):\n",
    "        loss = (1-y) * distance**2 + y * (torch.max(torch.zeros_like(distance), self.margin - distance)**2)\n",
    "        return torch.mean(loss, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f26caec",
   "metadata": {},
   "source": [
    "### Using two loss functions to minimize the error to distinguish the pairs and to predict the target class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "0fe455d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss, BCELoss\n",
    "from pytorch_metric_learning import losses\n",
    "\n",
    "contrastive_loss = ContrastiveLoss()\n",
    "cross_entropy_loss = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5b4a3a",
   "metadata": {},
   "source": [
    "### Padding the batches so that all the batches have same number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "e3b8586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def pad_batch(x1, x2, y0, y1, y2):\n",
    "    b_size = x1.shape[0]\n",
    "    pad_len = BATCH_SIZE - b_size\n",
    "    if pad_len > 0:\n",
    "        x1 = F.pad(x1, (0,0,0,0,0,pad_len))\n",
    "        x2 = F.pad(x2, (0,0,0,0,0,pad_len))\n",
    "        y0 = F.pad(y0, (0,0,0,pad_len))\n",
    "        y1 = F.pad(y1, (0,0,0,pad_len))\n",
    "        y2 = F.pad(y2, (0,0,0,pad_len))\n",
    "    return x1, x2, y0, y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "4e4877f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "\n",
    "def evaluate(model, dl):\n",
    "    model.eval()\n",
    "    all_y_pred, all_y_true = list(), list()\n",
    "    \n",
    "    for x1, x2, y0, y1, y2 in dl:\n",
    "        x1, x2, y0, y1, y2 = pad_batch(x1, x2, y0, y1, y2)\n",
    "        distance, y_hat = model(x1, x2)\n",
    "        \n",
    "        y = torch.bitwise_and(y1.type(torch.IntTensor), y2.type(torch.IntTensor))\n",
    "        \n",
    "        y_true = y.type(torch.FloatTensor)\n",
    "        y_pred = y_hat\n",
    "        \n",
    "        y_pred = (y_pred > 0.5).type(torch.FloatTensor)\n",
    "\n",
    "        all_y_pred.append(y_pred)\n",
    "        all_y_true.append(y_true)\n",
    "        \n",
    "    all_y_pred, all_y_true = vstack(all_y_pred), vstack(all_y_true)\n",
    "    acc, p, r, f1 = model_metrics(all_y_true.flatten(), all_y_pred.flatten())\n",
    "    print(f\"acc: {acc:.4f}, precision: {p:.4f}, recall: {r:.4f}, f1: {f1:.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "f0652c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    n_epochs = 10\n",
    "    model.train()\n",
    "    train_loss_arr = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0\n",
    "        for x1, x2, y0, y1, y2 in train_dl:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            x1, x2, y0, y1, y2 = pad_batch(x1, x2, y0, y1, y2)\n",
    "            distance, y_hat = model(x1, x2)\n",
    "            \n",
    "            y = torch.bitwise_and(y1.type(torch.IntTensor), y2.type(torch.IntTensor))\n",
    "            y_true = y.type(torch.FloatTensor)\n",
    "            y_pred = y_hat\n",
    "            \n",
    "            loss1 = cross_entropy_loss(y_pred, y_true)\n",
    "            loss2 = contrastive_loss(distance, y0)\n",
    "            loss = loss1 + loss2\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_dl)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.4f}'.format(epoch, train_loss))\n",
    "    evaluate(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca41348",
   "metadata": {},
   "source": [
    "### Training and Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "84dc0942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 1.4470\n",
      "acc: 0.9353, precision: 0.7315, recall: 0.8692, f1: 0.7803\n",
      "Epoch: 1 \tTraining Loss: 1.3312\n",
      "Epoch: 2 \tTraining Loss: 1.3037\n",
      "Epoch: 3 \tTraining Loss: 1.2976\n",
      "Epoch: 4 \tTraining Loss: 1.2820\n",
      "Epoch: 5 \tTraining Loss: 1.2705\n",
      "Epoch: 6 \tTraining Loss: 1.2696\n",
      "Epoch: 7 \tTraining Loss: 1.2676\n",
      "Epoch: 8 \tTraining Loss: 1.2618\n",
      "Epoch: 9 \tTraining Loss: 1.2594\n",
      "Epoch: 10 \tTraining Loss: 1.2617\n",
      "acc: 0.9348, precision: 0.7300, recall: 0.8668, f1: 0.7785\n",
      "Epoch: 11 \tTraining Loss: 1.2579\n",
      "Epoch: 12 \tTraining Loss: 1.2602\n",
      "Epoch: 13 \tTraining Loss: 1.2549\n",
      "Epoch: 14 \tTraining Loss: 1.2604\n",
      "Epoch: 15 \tTraining Loss: 1.2582\n",
      "Epoch: 16 \tTraining Loss: 1.2509\n",
      "Epoch: 17 \tTraining Loss: 1.2480\n",
      "Epoch: 18 \tTraining Loss: 1.2436\n",
      "Epoch: 19 \tTraining Loss: 1.2505\n",
      "acc: 0.9361, precision: 0.7337, recall: 0.8727, f1: 0.7830\n",
      "CPU times: user 52.4 s, sys: 5.2 s, total: 57.6 s\n",
      "Wall time: 44.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db015091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7-tf",
   "language": "python",
   "name": "py3.7-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
